{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from typing import Union, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "gpu_id = [0, 1]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(map(str, gpu_id))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder: str = \"/data/experience/CSV\"\n",
    "\n",
    "sub_folders: list = [\n",
    "    '/1.Deauth',\n",
    "    '/2.Disas',\n",
    "    '/3.(Re)Assoc',\n",
    "    '/4.Rogue_AP',\n",
    "    '/5.Krack',\n",
    "    '/6.Kr00k',\n",
    "    '/7.SSH',\n",
    "    '/8.Botnet',\n",
    "    '/9.Malware',\n",
    "    '/10.SQL_Injection',\n",
    "    '/11.SSDP',\n",
    "    '/12.Evil_Twin',\n",
    "    '/13.Website_spoofing'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "def load_fusion_dataset(idx: Union[int, List[int]], all: bool = False) -> pd.DataFrame:\n",
    "    res = []\n",
    "    \n",
    "    for sub_folder in sub_folders:\n",
    "        path: str = folder + sub_folder\n",
    "        files: list = os.listdir(path)\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=pd.errors.DtypeWarning)\n",
    "        \n",
    "            if all: df = pd.concat([pd.read_csv(path + '/' + file) for file in files])\n",
    "            elif type(idx) == list: df = pd.concat([pd.read_csv(path + '/' + files[i % len(files)]) for i in idx])\n",
    "            else: df = pd.read_csv(path + '/' + files[idx % len(files)])\n",
    "        \n",
    "        res.append(df)\n",
    "    \n",
    "    return pd.concat(res, axis=0)\n",
    "        \n",
    "\n",
    "def load_dataset(num: int = 1, all: bool = False) -> pd.DataFrame:\n",
    "    if num < 1 or num > 13: return None\n",
    "    \n",
    "    path: str = folder + sub_folders[num-1]\n",
    "    files: list = os.listdir(path)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=pd.errors.DtypeWarning)\n",
    "        df = pd.concat([pd.read_csv(path + '/' + file) for file in files], ignore_index=True) if all else pd.read_csv(path + '/' + files[0])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def wireless_preprocessing(df_copy: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Filter protocols related with wireless attacks\n",
    "    df_copy = df_copy[[col for col in df_copy.columns if col.startswith(('frame', 'radiotap', 'wlan', 'eapol', 'Label'))]]\n",
    "\n",
    "    df_copy = df_copy.dropna(subset=['Label'])\n",
    "\n",
    "    # fill NaN data\n",
    "    for col in ['frame.encap_type', 'frame.len', 'frame.number', 'frame.time_delta', 'frame.time_epoch',\n",
    "                'radiotap.channel.freq', 'radiotap.length', 'radiotap.timestamp.ts', 'wlan.fc.frag',\n",
    "                'wlan.fc.order', 'wlan.fc.moredata', 'wlan.fc.protected', 'wlan.fc.pwrmgt',\n",
    "                'wlan.fc.type', 'wlan.fc.retry', 'wlan.fc.subtype', 'wlan_radio.duration',\n",
    "                'wlan_radio.channel', 'wlan_radio.data_rate', 'wlan_radio.frequency',\n",
    "                'wlan_radio.signal_dbm', 'radiotap.datarate', 'radiotap.mactime', 'eapol.type']:\n",
    "        if col in df_copy.columns: \n",
    "            df_copy[col] = df_copy[col].fillna(-10000.0)\n",
    "    \n",
    "    df_copy['eapol.type'] = df_copy['eapol.type'].fillna(-1.0)\n",
    "    df_copy['eapol.len'] = df_copy['eapol.len'].fillna(0.0)\n",
    "    df_copy['eapol.keydes.replay_counter'] = df_copy['eapol.keydes.replay_counter'].fillna(-1.0)\n",
    "    df_copy['eapol.keydes.key_len'] = df_copy['eapol.keydes.key_len'].fillna(0.0)\n",
    "    df_copy['wlan.duration'] = df_copy['wlan.duration'].fillna(0.0) \n",
    "    df_copy['wlan_radio.timestamp'] = df_copy['wlan_radio.timestamp'].fillna(0.0) \n",
    "    df_copy['radiotap.dbm_antsignal'] = df_copy['radiotap.dbm_antsignal'].fillna(-1000)\n",
    "    df_copy['radiotap.rxflags'] = df_copy['radiotap.rxflags'].fillna('0xffffffff')\n",
    "    df_copy['wlan.fc.ds'] = df_copy['wlan.fc.ds'].fillna('0xffffffff')\n",
    "    df_copy['wlan_radio.phy'] = df_copy['wlan_radio.phy'].fillna(-1000.0)\n",
    "    \n",
    "    df_copy.loc[df_copy['wlan_radio.phy'] == 'Normal', 'wlan_radio.phy'] = -1000.0\n",
    "\n",
    "    # Change type of several flags columns\n",
    "    df_copy.loc[:, 'radiotap.rxflags'] = df_copy['radiotap.rxflags'].apply(lambda x: int(x, 16) if type(x)==str else x)\n",
    "    df_copy.loc[:, 'wlan_radio.phy'] = df_copy['wlan_radio.phy'].apply(lambda x: float(x) if type(x)==str else x)\n",
    "    df_copy.loc[:, 'Label'] = df_copy['Label'].apply(lambda x: x != 'Normal')\n",
    "    df_copy.loc[:, 'radiotap.present.tsft'] = df_copy['radiotap.present.tsft'].apply(lambda x: x == '1-0-0')\n",
    "    df_copy.loc[:, 'radiotap.dbm_antsignal'] = df_copy['radiotap.dbm_antsignal'].apply(lambda x: float(x) if isinstance(x, (int, float)) else (float(x) if '.' in x else -int(x.split('-')[1])))\n",
    "    df_copy.loc[:, 'wlan.fc.ds'] = df_copy['wlan.fc.ds'].apply(lambda x: x if isinstance(x, (int, float)) else int(x, 16))\n",
    "    df_copy.loc[:, 'wlan.country_info.fnm'] = df_copy['wlan.country_info.fnm'].apply(lambda x: x if not isinstance(x, (int, float)) else x)\n",
    "    df_copy.loc[:, 'wlan.analysis.has_key'] = df_copy['wlan.analysis.kck'].isna()\n",
    "    df_copy.loc[:, 'wlan.fixed.used'] = df_copy['wlan.fixed.timestamp'].notna()\n",
    "    df_copy.loc[:, 'wlan.rsn.used'] = df_copy['wlan.rsn.ie.gtk.key'].notna()\n",
    "    df_copy.loc[:, 'eapol.used'] = df_copy['eapol.type'].notna()\n",
    "    \n",
    "    df_copy = df_copy.astype({\n",
    "        'radiotap.channel.flags.cck': 'bool', \n",
    "        'radiotap.channel.flags.ofdm': 'bool', \n",
    "        'Label': 'bool',\n",
    "        'radiotap.present.tsft': 'bool',\n",
    "        'radiotap.dbm_antsignal': 'int64',\n",
    "        'radiotap.rxflags': 'int64',\n",
    "        'wlan.fc.ds': 'int64'\n",
    "    })\n",
    "\n",
    "    # delete unnecessary columns\n",
    "    drop_columns = [\n",
    "        'frame.time', 'frame.time_delta_displayed', 'frame.time_relative',\n",
    "        'wlan.analysis.kck', 'wlan.analysis.kek', 'wlan_radio.end_tsf', 'wlan_radio.start_tsf'\n",
    "    ]\n",
    "    df_copy = df_copy.drop(columns=drop_columns, axis=1)\n",
    "    df_copy = df_copy[[col for col in df_copy.columns if not col.startswith(('wlan.fixed', 'wlan.rsn', 'wlan_rsn'))]]\n",
    "\n",
    "    # Fill category data\n",
    "    df_copy['wlan.bssid'] = df_copy['wlan.bssid'].fillna('-')\n",
    "    df_copy['wlan.country_info.fnm'] = df_copy['wlan.country_info.fnm'].fillna('-')\n",
    "    df_copy['wlan.country_info.code'] = df_copy['wlan.country_info.code'].fillna('-')\n",
    "    df_copy['wlan.da'] = df_copy['wlan.da'].fillna('-')\n",
    "    df_copy['wlan.sa'] = df_copy['wlan.sa'].fillna('-')\n",
    "    df_copy['wlan.ta'] = df_copy['wlan.ta'].fillna('-')\n",
    "    df_copy['wlan.tag'] = df_copy['wlan.tag'].fillna('-')\n",
    "    df_copy['wlan.tag.length'] = df_copy['wlan.tag.length'].fillna('-')\n",
    "    df_copy['wlan.seq'] = df_copy['wlan.seq'].fillna(-1.0)\n",
    "    df_copy['wlan.ssid'] = df_copy['wlan.ssid'].fillna('Unknown')\n",
    "    \n",
    "    df_copy = df_copy.dropna(how='all', axis=1)\n",
    "\n",
    "    for col in df_copy.select_dtypes('object').columns:\n",
    "        le = LabelEncoder()\n",
    "        df_copy[col] = le.fit_transform(df_copy[col])\n",
    "    \n",
    "    features = df_copy.drop(columns=['Label'])\n",
    "    label = df_copy['Label']\n",
    "    \n",
    "    scaler = StandardScaler().fit(features)\n",
    "    scaled_features = pd.DataFrame(scaler.transform(features), columns=features.columns)\n",
    "    \n",
    "    return pd.concat([scaled_features.reset_index(drop=True), label.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_dataset(num: int = None) -> tuple:\n",
    "    if num: df = load_dataset(num, True)\n",
    "    else: df = load_fusion_dataset(random.randint(0, 10))\n",
    "    \n",
    "    df = wireless_preprocessing(df)\n",
    "    \n",
    "    df_normal = df[df['Label'] == False]\n",
    "    df_attack = df[df['Label'] == True]\n",
    "    \n",
    "    df_normal_features = df_normal.drop(columns=['Label'])\n",
    "    df_normal_labels = df_normal['Label']\n",
    "    \n",
    "    df_attack_features = df_attack.drop(columns=['Label'])\n",
    "    df_attack_labels = df_attack['Label']\n",
    "    \n",
    "    return df_normal_features, df_normal_labels, df_attack_features, df_attack_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim, hidden_dim=16):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, encoding_dim),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderClassifier(nn.Module):\n",
    "    def __init__(self, encoder, clf):\n",
    "        super(AutoencoderClassifier, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.clf = clf\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.clf(x)\n",
    "        return x\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        X_tensor = torch.tensor(X.values, dtype=torch.float32).to(device)\n",
    "        self.clf.fit(self.encoder(X_tensor).cpu().detach().numpy(), y)\n",
    "    \n",
    "    def predict(self, x: pd.DataFrame):\n",
    "        X_tensor = torch.tensor(x.values, dtype=torch.float32).to(device)\n",
    "        x = self.encoder(X_tensor).cpu().detach().numpy()\n",
    "        x = self.clf.predict(x)\n",
    "        return x\n",
    "    \n",
    "    def predict_proba(self, x: pd.DataFrame):\n",
    "        X_tensor = torch.tensor(x.values, dtype=torch.float32).to(device)\n",
    "        x = self.encoder(X_tensor).cpu().detach().numpy()\n",
    "        x = self.clf.predict_proba(x)\n",
    "        return x\n",
    "    \n",
    "    def __call__(self, x: pd.DataFrame):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred) -> list:\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    return [accuracy, precision, recall, f1]\n",
    "    \n",
    "def get_model_eval(model, X_test = None, y_test = None):\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    res = get_clf_eval(y_test, pred)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_sample_dataset(idx: int = None, train: bool = True, num: int = 100) -> tuple:\n",
    "    path: str = \"/data/experience/wireless/CSV/\"\n",
    "    sub_folders: list = [\n",
    "        'Deauth_',\n",
    "        'Disas_',\n",
    "        '(Re)Assoc_',\n",
    "        'Rogue_AP_',\n",
    "        'Krack_',\n",
    "        'Kr00k_',\n",
    "        'SSH_',\n",
    "        'Botnet_',\n",
    "        'Malware_',\n",
    "        'SQL_Injection_',\n",
    "        'SSDP_',\n",
    "        'Evil_Twin_',\n",
    "        'Website_spoofing_'\n",
    "    ]\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=pd.errors.DtypeWarning)\n",
    "\n",
    "        if train: df = pd.read_csv(path + \"train/\" + sub_folders[idx-1] + str(num) + '_train.csv')\n",
    "        else: df = pd.read_csv(path + \"test/\" + sub_folders[idx-1] + 'test.csv')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df_train: pd.DataFrame, df_test: pd.DataFrame, WiFIDS: bool) -> pd.DataFrame:\n",
    "    if WiFIDS:\n",
    "        warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "        \n",
    "        df_train = wireless_preprocessing(df_train)\n",
    "        df_test = wireless_preprocessing(df_test)\n",
    "        \n",
    "    else:\n",
    "        df_train = df_train.dropna(subset=['Label'])\n",
    "        df_test = df_test.dropna(subset=['Label'])\n",
    "        \n",
    "        df_train.loc[:, 'Label'] = df_train['Label'].apply(lambda x: x != 'Normal')\n",
    "        df_test.loc[:, 'Label'] = df_train['Label'].apply(lambda x: x != 'Normal')\n",
    "        df_train = df_train.astype({'Label':'bool'})\n",
    "        df_test = df_test.astype({'Label':'bool'})\n",
    "        \n",
    "        df_deletion = list(set(df_train.select_dtypes('object').columns)|set(df_test.select_dtypes('object').columns))\n",
    "        \n",
    "        df_train = df_train.drop(columns=df_deletion)\n",
    "        df_test = df_test.drop(columns=df_deletion)\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_performance(model_data):\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "    num_metrics = len(metrics)\n",
    "    models = list(model_data.keys())\n",
    "    num_models = len(models)\n",
    "\n",
    "    # Creating a list for each metric containing scores for all models\n",
    "    scores = {metric: [model_data[model][i] * 100 for model in models] for i, metric in enumerate(metrics)}\n",
    "\n",
    "    # Setting up the plot\n",
    "    fig, ax = plt.subplots()\n",
    "    index = np.arange(num_metrics)\n",
    "    bar_width = 0.2\n",
    "\n",
    "    # Plotting data for each model\n",
    "    for i, model in enumerate(models):\n",
    "        bar_positions = index + (i * bar_width)\n",
    "        ax.bar(bar_positions, [scores[metric][i] for metric in metrics], bar_width, label=model)\n",
    "\n",
    "    # Adding labels, title, and legend\n",
    "    ax.set_xlabel('Metrics')\n",
    "    ax.set_ylabel('Scores (%)')\n",
    "    ax.set_title('Model Performance Comparison')\n",
    "    ax.set_xticks(index + bar_width * (num_models - 1) / 2)\n",
    "    ax.set_xticklabels(metrics)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Datasets for pretrain\n",
    "df_normal_features, df_normal_labels, _, _ = load_and_split_dataset()\n",
    "\n",
    "sampling_idx = random.sample(range(len(df_normal_features)), 10000)\n",
    "df_normal_features_sampled = df_normal_features.iloc[sampling_idx]\n",
    "\n",
    "df_normal_features_tensor = torch.tensor(df_normal_features_sampled.values, dtype=torch.float32).to(device)\n",
    "normal_dataset = TensorDataset(df_normal_features_tensor)\n",
    "normal_loader = DataLoader(normal_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pretrain Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = df_normal_features.shape[1]\n",
    "encoding_dim = 16\n",
    "\n",
    "model = Autoencoder(input_dim, encoding_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the autoencoder\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    cnt = 0\n",
    "    for data in normal_loader:\n",
    "        outputs = model(data[0])\n",
    "        loss = criterion(outputs, data[0])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Autoencoder(input_dim, encoding_dim).to(device)\n",
    "# model.load_state_dict(torch.load('autoencoder.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Comparison with pure classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in [1, 2, 3, 4, 5, 6, 12]:\n",
    "    print(\"[Test {}: {}] ==========\".format(idx, sub_folders[idx-1].split(\".\")[1]))\n",
    "    \n",
    "    train_sampled = load_and_sample_dataset(idx, True, 1000)\n",
    "    test_sampled = load_and_sample_dataset(idx, False)\n",
    "    \n",
    "    train_WiFIDS, test_WiFIDS = preprocessing(train_sampled, test_sampled, True)\n",
    "    train_df, test_df = preprocessing(train_sampled, test_sampled, False)\n",
    "    \n",
    "    train_WiFIDS_features = train_WiFIDS.drop(columns=['Label'])\n",
    "    train_WiFIDS_label = train_WiFIDS['Label']\n",
    "    test_WiFIDS_features = test_WiFIDS.drop(columns=['Label'])\n",
    "    test_WiFIDS_label = test_WiFIDS['Label']\n",
    "    \n",
    "    train_df_features = train_df.drop(columns=['Label'])\n",
    "    train_df_label = train_df['Label']\n",
    "    test_df_features = test_df.drop(columns=['Label'])\n",
    "    test_df_label = test_df['Label']\n",
    "    \n",
    "    dt_encoding_clf = DecisionTreeClassifier()\n",
    "    dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "    WiFIDS = AutoencoderClassifier(model.encoder, dt_encoding_clf)\n",
    "    \n",
    "    WiFIDS.fit(train_WiFIDS_features, train_WiFIDS_label)\n",
    "    dt_clf.fit(train_df_features, train_df_label)\n",
    "    \n",
    "    WiFIDS_score = get_model_eval(WiFIDS, test_WiFIDS_features, test_WiFIDS_label)\n",
    "    dt_clf_score = get_model_eval(dt_clf, test_df_features, test_df_label)\n",
    "    \n",
    "    print(\"==========================\")\n",
    "    \n",
    "    plot_model_performance({\n",
    "        'WiFIDS': WiFIDS_score,\n",
    "        'DecisionTree': dt_clf_score\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Comparison of Total Detection Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_sampled = []\n",
    "test_sampled = []\n",
    "\n",
    "for idx in [1, 2, 3, 4, 5, 6, 12]: train_sampled.append(load_and_sample_dataset(idx, True, 1000))\n",
    "for idx in [1, 2, 3, 4, 5, 6, 12]: test_sampled.append(load_and_sample_dataset(idx, False))\n",
    "\n",
    "train_sampled = pd.concat(train_sampled, axis=0, ignore_index=True)\n",
    "test_sampled = pd.concat(test_sampled, axis=0, ignore_index=True)\n",
    "\n",
    "train_WiFIDS, test_WiFIDS = preprocessing(train_sampled, test_sampled, True)\n",
    "train_df, test_df = preprocessing(train_sampled, test_sampled, False)\n",
    "\n",
    "train_WiFIDS_features = train_WiFIDS.drop(columns=['Label'])\n",
    "train_WiFIDS_label = train_WiFIDS['Label']\n",
    "test_WiFIDS_features = test_WiFIDS.drop(columns=['Label'])\n",
    "test_WiFIDS_label = test_WiFIDS['Label']\n",
    "\n",
    "train_df_features = train_df.drop(columns=['Label'])\n",
    "train_df_label = train_df['Label']\n",
    "test_df_features = test_df.drop(columns=['Label'])\n",
    "test_df_label = test_df['Label']\n",
    "\n",
    "dt_encoding_clf = DecisionTreeClassifier()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "WiFIDS = AutoencoderClassifier(model.encoder, dt_encoding_clf)\n",
    "\n",
    "WiFIDS.fit(train_WiFIDS_features, train_WiFIDS_label)\n",
    "dt_clf.fit(train_df_features, train_df_label)\n",
    "\n",
    "WiFIDS_score = get_model_eval(WiFIDS, test_WiFIDS_features, test_WiFIDS_label)\n",
    "dt_clf_score = get_model_eval(dt_clf, test_df_features, test_df_label)\n",
    "\n",
    "print(\"==========================\")\n",
    "\n",
    "plot_model_performance({\n",
    "    'WiFIDS': WiFIDS_score,\n",
    "    'DecisionTree': dt_clf_score\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Compare with other model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in [1, 2, 3, 4, 5, 6, 12]:\n",
    "    train_sampled = load_and_sample_dataset(idx, True, 1000)\n",
    "    test_sampled = load_and_sample_dataset(idx, False)\n",
    "    \n",
    "    train_WiFIDS, test_WiFIDS = preprocessing(train_sampled, test_sampled, True)\n",
    "    train_df, test_df = preprocessing(train_sampled, test_sampled, False)\n",
    "    \n",
    "    train_WiFIDS_features = train_WiFIDS.drop(columns=['Label'])\n",
    "    train_WiFIDS_label = train_WiFIDS['Label']\n",
    "    test_WiFIDS_features = test_WiFIDS.drop(columns=['Label'])\n",
    "    test_WiFIDS_label = test_WiFIDS['Label']\n",
    "    \n",
    "    train_df_features = train_df.drop(columns=['Label'])\n",
    "    train_df_label = train_df['Label']\n",
    "    test_df_features = test_df.drop(columns=['Label'])\n",
    "    test_df_label = test_df['Label']\n",
    "    \n",
    "    WiFIDS_rf = AutoencoderClassifier(model.encoder, RandomForestClassifier())\n",
    "    rf_clf = RandomForestClassifier()\n",
    "\n",
    "    WiFIDS = AutoencoderClassifier(model.encoder, dt_encoding_clf)\n",
    "    \n",
    "    WiFIDS.fit(train_WiFIDS_features, train_WiFIDS_label)\n",
    "    rf_clf.fit(train_df_features, train_df_label)\n",
    "    \n",
    "    WiFIDS_score = get_model_eval(WiFIDS, test_WiFIDS_features, test_WiFIDS_label)\n",
    "    dt_clf_score = get_model_eval(rf_clf, test_df_features, test_df_label)\n",
    "    \n",
    "    print(\"==========================\")\n",
    "    \n",
    "    plot_model_performance({\n",
    "        'WiFIDS': WiFIDS_score,\n",
    "        'DecisionTree': dt_clf_score\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in [1, 2, 3, 4, 5, 6, 12]:\n",
    "    print(\"[Test {}: {}] ==========\".format(idx, sub_folders[idx-1].split(\".\")[1]))\n",
    "    \n",
    "    train_sampled = load_and_sample_dataset(idx)\n",
    "    test_sampled = load_and_sample_dataset(idx, False)\n",
    "    \n",
    "    train_WiFIDS, test_WiFIDS = preprocessing(train_sampled, test_sampled, True)\n",
    "    train_df, test_df = preprocessing(train_sampled, test_sampled, False)\n",
    "    \n",
    "    train_WiFIDS_features = train_WiFIDS.drop(columns=['Label'])\n",
    "    train_WiFIDS_label = train_WiFIDS['Label']\n",
    "    test_WiFIDS_features = test_WiFIDS.drop(columns=['Label'])\n",
    "    test_WiFIDS_label = test_WiFIDS['Label']\n",
    "    \n",
    "    train_df_features = train_df.drop(columns=['Label'])\n",
    "    train_df_label = train_df['Label']\n",
    "    test_df_features = test_df.drop(columns=['Label'])\n",
    "    test_df_label = test_df['Label']\n",
    "    \n",
    "    WiFIDS_rf = AutoencoderClassifier(model.encoder, RandomForestClassifier())\n",
    "    rf_clf = RandomForestClassifier()\n",
    "\n",
    "    WiFIDS = AutoencoderClassifier(model.encoder, dt_encoding_clf)\n",
    "    \n",
    "    WiFIDS.fit(train_WiFIDS_features, train_WiFIDS_label)\n",
    "    rf_clf.fit(train_df_features, train_df_label)\n",
    "    \n",
    "    WiFIDS_score = get_model_eval(WiFIDS, test_WiFIDS_features, test_WiFIDS_label)\n",
    "    rf_clf_score = get_model_eval(rf_clf, test_df_features, test_df_label)\n",
    "    \n",
    "    print(\"==========================\")\n",
    "    \n",
    "    plot_model_performance({\n",
    "        'WiFIDS': WiFIDS_score,\n",
    "        'DecisionTree': rf_clf_score\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Comparison of Accuracy Based on Number of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipsagi = []\n",
    "\n",
    "for idx in [4, 5, 6, 12]:\n",
    "    results = {}\n",
    "    print(\"[Test {}: {}] ==========\".format(idx, sub_folders[idx-1].split(\".\")[1]))\n",
    "    \n",
    "    for num in [3, 5, 10, 20, 50, 100, 150, 200, 300, 500, 800, 1000]:\n",
    "        \n",
    "        train_sampled = load_and_sample_dataset(idx, True, num)\n",
    "        test_sampled = load_and_sample_dataset(idx, False)\n",
    "        \n",
    "        train_WiFIDS, test_WiFIDS = preprocessing(train_sampled, test_sampled, True)\n",
    "        train_df, test_df = preprocessing(train_sampled, test_sampled, False)\n",
    "        \n",
    "        train_WiFIDS_features = train_WiFIDS.drop(columns=['Label'])\n",
    "        train_WiFIDS_label = train_WiFIDS['Label']\n",
    "        test_WiFIDS_features = test_WiFIDS.drop(columns=['Label'])\n",
    "        test_WiFIDS_label = test_WiFIDS['Label']\n",
    "        \n",
    "        train_df_features = train_df.drop(columns=['Label'])\n",
    "        train_df_label = train_df['Label']\n",
    "        test_df_features = test_df.drop(columns=['Label'])\n",
    "        test_df_label = test_df['Label']\n",
    "        \n",
    "        dt_encoding_clf = DecisionTreeClassifier()\n",
    "\n",
    "        WiFIDS = AutoencoderClassifier(model.encoder, dt_encoding_clf)\n",
    "        WiFIDS.fit(train_WiFIDS_features, train_WiFIDS_label)\n",
    "        WiFIDS_score = get_model_eval(WiFIDS, test_WiFIDS_features, test_WiFIDS_label)\n",
    "        \n",
    "        results.update({num: WiFIDS_score})\n",
    "        \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    shipsagi.append(results)\n",
    "    \n",
    "    accuracy = list(data[0] for data in results.values())\n",
    "    precision = list(data[1] for data in results.values())\n",
    "    recall = list(data[2] for data in results.values())\n",
    "    f1 = list(data[3] for data in results.values())\n",
    "    \n",
    "    plt.plot(results.keys(), accuracy, marker='o', linestyle='-', color='b', label=\"Accuracy\")\n",
    "    plt.plot(results.keys(), precision, marker='o', linestyle='-', color='r', label=\"Precision\")\n",
    "    plt.plot(results.keys(), recall, marker='o', linestyle='-', color='g', label=\"Recall\")\n",
    "    plt.plot(results.keys(), f1, marker='o', linestyle='-', color='m', label=\"F1\")\n",
    "    \n",
    "    \n",
    "    plt.title('Accuracy vs Number of Training Rows')\n",
    "    plt.xlabel('Number of Training Rows')\n",
    "    plt.ylabel('Score')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, s, d, f = shipsagi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_sum(data1, data2):\n",
    "    avg_sum = {}\n",
    "    for key in data1:\n",
    "        avg_sum[key] = [(v1 + v2) / 2 for v1, v2 in zip(data1[key], data2[key])]\n",
    "    return avg_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = a\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "accuracy = list(data[0] for data in results.values())\n",
    "precision = list(data[1] for data in results.values())\n",
    "recall = list(data[2] for data in results.values())\n",
    "f1 = list(data[3] for data in results.values())\n",
    "\n",
    "plt.plot(results.keys(), accuracy, marker='o', linestyle='-', color='b', label=\"Accuracy\")\n",
    "plt.plot(results.keys(), precision, marker='o', linestyle='-', color='r', label=\"Precision\")\n",
    "plt.plot(results.keys(), recall, marker='o', linestyle='-', color='g', label=\"Recall\")\n",
    "plt.plot(results.keys(), f1, marker='o', linestyle='-', color='m', label=\"F1\")\n",
    "\n",
    "\n",
    "plt.title('Accuracy vs Number of Training Rows')\n",
    "plt.xlabel('Number of Training Rows')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
